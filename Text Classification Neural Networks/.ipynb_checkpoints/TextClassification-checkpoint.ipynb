{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keras.datasets.imdb\n",
    "#only take the 10000 most common words (more rare words could mess up the model)\n",
    "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=88000)\n",
    "\n",
    "word_index = data.get_word_index()\n",
    "word_index = {k:(v+3) for k, v in word_index.items()}\n",
    "\n",
    "word_index['<PAD>'] = 0\n",
    "word_index['<START>'] = 1\n",
    "word_index['<UNK>'] = 2\n",
    "word_index['<UNUSED>'] = 3\n",
    "\n",
    "#make value the key (we need the int values to point at their associated words)\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "#add padding for reviews less than 250 words\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index['<PAD>'], padding='post', maxlen=250)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index['<PAD>'], padding='post', maxlen=250)\n",
    "\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START>pleasegivethisoneamissbrbrkristyswansonandtherestofthecastrenderedterribleperformancestheshowisflatflatflatbrbridon'tknowhowmichaelmadisoncouldhaveallowedthisoneonhisplatehealmostseemedtoknowthiswasn'tgoingtoworkoutandhisperformancewasquitelacklustresoallyoumadisonfansgivethisamiss<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n"
     ]
    }
   ],
   "source": [
    "def decode_review(text):\n",
    "    return \"\".join([reverse_word_index.get(i, \"?\") for i in text])\n",
    "\n",
    "print(decode_review(test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "30/30 [==============================] - 2s 79ms/step - loss: 0.6927 - accuracy: 0.5073 - val_loss: 0.6918 - val_accuracy: 0.6112\n",
      "Epoch 2/40\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.6896 - accuracy: 0.6073 - val_loss: 0.6868 - val_accuracy: 0.7368\n",
      "Epoch 3/40\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.6808 - accuracy: 0.7611 - val_loss: 0.6748 - val_accuracy: 0.7397\n",
      "Epoch 4/40\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.6622 - accuracy: 0.7743 - val_loss: 0.6522 - val_accuracy: 0.7808\n",
      "Epoch 5/40\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.6292 - accuracy: 0.8067 - val_loss: 0.6168 - val_accuracy: 0.7925\n",
      "Epoch 6/40\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.5837 - accuracy: 0.8192 - val_loss: 0.5735 - val_accuracy: 0.8035\n",
      "Epoch 7/40\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.5301 - accuracy: 0.8393 - val_loss: 0.5249 - val_accuracy: 0.8189\n",
      "Epoch 8/40\n",
      "30/30 [==============================] - 2s 54ms/step - loss: 0.4738 - accuracy: 0.8571 - val_loss: 0.4790 - val_accuracy: 0.8321\n",
      "Epoch 9/40\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.4212 - accuracy: 0.8742 - val_loss: 0.4388 - val_accuracy: 0.8426\n",
      "Epoch 10/40\n",
      "30/30 [==============================] - 2s 56ms/step - loss: 0.3748 - accuracy: 0.8894 - val_loss: 0.4064 - val_accuracy: 0.8524\n",
      "Epoch 11/40\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.3355 - accuracy: 0.9001 - val_loss: 0.3784 - val_accuracy: 0.8610\n",
      "Epoch 12/40\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.3022 - accuracy: 0.9081 - val_loss: 0.3570 - val_accuracy: 0.8676\n",
      "Epoch 13/40\n",
      "30/30 [==============================] - 2s 58ms/step - loss: 0.2743 - accuracy: 0.9152 - val_loss: 0.3399 - val_accuracy: 0.8717\n",
      "Epoch 14/40\n",
      "30/30 [==============================] - 2s 56ms/step - loss: 0.2495 - accuracy: 0.9246 - val_loss: 0.3262 - val_accuracy: 0.8756\n",
      "Epoch 15/40\n",
      "30/30 [==============================] - 2s 55ms/step - loss: 0.2283 - accuracy: 0.9305 - val_loss: 0.3153 - val_accuracy: 0.8785\n",
      "Epoch 16/40\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.2097 - accuracy: 0.9373 - val_loss: 0.3060 - val_accuracy: 0.8815\n",
      "Epoch 17/40\n",
      "30/30 [==============================] - 3s 86ms/step - loss: 0.1925 - accuracy: 0.9437 - val_loss: 0.2992 - val_accuracy: 0.8835\n",
      "Epoch 18/40\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.1775 - accuracy: 0.9486 - val_loss: 0.2933 - val_accuracy: 0.8856\n",
      "Epoch 19/40\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.1636 - accuracy: 0.9535 - val_loss: 0.2883 - val_accuracy: 0.8869\n",
      "Epoch 20/40\n",
      "30/30 [==============================] - 2s 59ms/step - loss: 0.1512 - accuracy: 0.9587 - val_loss: 0.2848 - val_accuracy: 0.8873\n",
      "Epoch 21/40\n",
      "30/30 [==============================] - 3s 91ms/step - loss: 0.1400 - accuracy: 0.9625 - val_loss: 0.2817 - val_accuracy: 0.8875ccuracy: \n",
      "Epoch 22/40\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.1297 - accuracy: 0.9664 - val_loss: 0.2794 - val_accuracy: 0.8884\n",
      "Epoch 23/40\n",
      "30/30 [==============================] - 2s 58ms/step - loss: 0.1204 - accuracy: 0.9701 - val_loss: 0.2777 - val_accuracy: 0.8888\n",
      "Epoch 24/40\n",
      "30/30 [==============================] - 2s 76ms/step - loss: 0.1116 - accuracy: 0.9732 - val_loss: 0.2774 - val_accuracy: 0.8889\n",
      "Epoch 25/40\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.1037 - accuracy: 0.9765 - val_loss: 0.2771 - val_accuracy: 0.8877\n",
      "Epoch 26/40\n",
      "30/30 [==============================] - 2s 78ms/step - loss: 0.0964 - accuracy: 0.9788 - val_loss: 0.2762 - val_accuracy: 0.8903\n",
      "Epoch 27/40\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.0894 - accuracy: 0.9810 - val_loss: 0.2760 - val_accuracy: 0.8905\n",
      "Epoch 28/40\n",
      "30/30 [==============================] - 2s 79ms/step - loss: 0.0832 - accuracy: 0.9832 - val_loss: 0.2776 - val_accuracy: 0.8900\n",
      "Epoch 29/40\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.0778 - accuracy: 0.9846 - val_loss: 0.2779 - val_accuracy: 0.8901\n",
      "Epoch 30/40\n",
      "30/30 [==============================] - 2s 81ms/step - loss: 0.0725 - accuracy: 0.9856 - val_loss: 0.2786 - val_accuracy: 0.8900\n",
      "Epoch 31/40\n",
      "30/30 [==============================] - 2s 75ms/step - loss: 0.0675 - accuracy: 0.9877 - val_loss: 0.2814 - val_accuracy: 0.8901\n",
      "Epoch 32/40\n",
      "30/30 [==============================] - 2s 65ms/step - loss: 0.0630 - accuracy: 0.9885 - val_loss: 0.2826 - val_accuracy: 0.8901\n",
      "Epoch 33/40\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0590 - accuracy: 0.9895 - val_loss: 0.2843 - val_accuracy: 0.8897\n",
      "Epoch 34/40\n",
      "30/30 [==============================] - 2s 65ms/step - loss: 0.0549 - accuracy: 0.9911 - val_loss: 0.2859 - val_accuracy: 0.8895\n",
      "Epoch 35/40\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.0515 - accuracy: 0.9911 - val_loss: 0.2880 - val_accuracy: 0.8888\n",
      "Epoch 36/40\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.0482 - accuracy: 0.9923 - val_loss: 0.2944 - val_accuracy: 0.8860\n",
      "Epoch 37/40\n",
      "30/30 [==============================] - 2s 64ms/step - loss: 0.0455 - accuracy: 0.9922 - val_loss: 0.2922 - val_accuracy: 0.8887\n",
      "Epoch 38/40\n",
      "30/30 [==============================] - 2s 63ms/step - loss: 0.0424 - accuracy: 0.9938 - val_loss: 0.2965 - val_accuracy: 0.8876\n",
      "Epoch 39/40\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.0405 - accuracy: 0.9943 - val_loss: 0.2982 - val_accuracy: 0.8889\n",
      "Epoch 40/40\n",
      "30/30 [==============================] - 2s 63ms/step - loss: 0.0375 - accuracy: 0.9945 - val_loss: 0.3004 - val_accuracy: 0.8875\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.3350 - accuracy: 0.8721\n",
      "[0.33496516942977905, 0.8720800280570984]\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(88000, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "x_val = train_data[:10000]\n",
    "x_train = train_data[10000:]\n",
    "y_val = train_labels[:10000]\n",
    "y_train = train_labels[10000:]\n",
    "\n",
    "fit_model = model.fit(x_train, y_train, epochs=40, batch_size=512, verbose=1, validation_data=(x_val, y_val))\n",
    "results = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \n",
      "<START>pleasegivethisoneamissbrbrkristyswansonandtherestofthecastrenderedterribleperformancestheshowisflatflatflatbrbridon'tknowhowmichaelmadisoncouldhaveallowedthisoneonhisplatehealmostseemedtoknowthiswasn'tgoingtoworkoutandhisperformancewasquitelacklustresoallyoumadisonfansgivethisamiss<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "Prediction: [5.9995104e-18]\n",
      "Actual: 0\n",
      "[0.33496516942977905, 0.8720800280570984]\n"
     ]
    }
   ],
   "source": [
    "test_review = test_data[0]\n",
    "predict = model.predict([test_review])\n",
    "print(\"Review: \")\n",
    "print(decode_review(test_review))\n",
    "print(\"Prediction: \" + str(predict[0]))\n",
    "print(\"Actual: \" + str(test_labels[0]))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story: When the royal lion cub, Simba is born to Queen Sarabi and King Mufasa, animals in the forest rejoice at having a new heir. But their joy is short-lived when Mufasa dies trying to save little Simbaâ€™s life. Feeling guilty for being the cause of his fatherâ€™s death Simba runs away from the forest. And now his evil uncle Scar takes over the throne.\n",
      "\n",
      "[[ 963    2    6  830    2 2023    6 1964   13 3363 1331    2    6    2\n",
      "  3363  963 1992    2 2023  963   13 1479    2    2    2 1206  830    2\n",
      "   830 2023  963   13 1479    2 1468 1604 5135    2   13  590    2  590\n",
      "  2023 1604 1479  830    2 2014   13 1964  963 1095    2 1992 2023  963\n",
      "  3363    2    2 1206 1209    6  590    6    2 1095   13  963  590    2\n",
      "   830 1479 5135   13 3363 1331    2  830 1604    2  590    6 1964  963\n",
      "     2 2014   13  830  830 2014  963    2    2   13 1983  503    6    2\n",
      "     2    2  590    2 2014   13 1209  963    2    2    2  963  963 2014\n",
      "    13 3363 1331    2 1331 1206   13 2014  830 5135    2 1209 1604 1479\n",
      "     2  503  963   13 3363 1331    2  830 2023  963    2 1148    6 1206\n",
      "   590  963    2 1604 1209    2 2023   13  590    2 1209    6  830 2023\n",
      "   963 1479    2    2    2  590    2 1095  963    6  830 2023    2    2\n",
      "    13 1983  503    6    2 1479 1206 3363  590    2    6 1992    6 5135\n",
      "     2 1209 1479 1604 1983    2  830 2023  963    2 1209 1604 1479  963\n",
      "   590  830    2    2    2 3363 1095    2 3363 1604 1992    2 2023   13\n",
      "   590    2  963 1964   13 2014    2 1206 3363 1148 2014  963    2    2\n",
      "  1148    6 1479    2  830    6 2295  963  590    2 1604 1964  963 1479\n",
      "     2  830 2023  963    2  830 2023 1479 1604 3363  963    2]]\n",
      "[3.5285364e-06]\n",
      "Review: 2019â€™s The Lion King is a â€˜live actionâ€™ remake of the 1994 original animation flick which went on to become an iconic film for all ages. Those who have watched the original Lion King will vouch for its strong emotional connect, rousing, heartbreaking moments that left a lasting impression and of course the legendary soundtrack and background score.\n",
      "\n",
      "[[ 830 1604    2  503  963 1148 1604 1983  963    2    6 3363    2   13\n",
      "  1148 1604 3363   13 1148    2 1209   13 2014 1983    2 1209 1604 1479\n",
      "     2    6 2014 2014    2    6 1331  963  590    2    2    2 2023 1604\n",
      "   590  963    2 1992 2023 1604    2 2023    6 1964  963    2 1992    6\n",
      "   830 1148 2023  963 1095    2  830 2023  963    2 1604 1479   13 1331\n",
      "    13 3363    6 2014    2    2   13 1604 3363    2    2   13 3363 1331\n",
      "     2 1992   13 2014 2014    2 1964 1604 1206 1148 2023    2 1209 1604\n",
      "  1479    2   13  830  590    2  590  830 1479 1604 3363 1331    2  963\n",
      "  1983 1604  830   13 1604 3363    6 2014    2 1148 1604 3363 3363  963\n",
      "  1148  830    2 1479 1604 1206  590   13 3363 1331    2 2023  963    6\n",
      "  1479  830  503 1479  963    6 2295   13 3363 1331    2 1983 1604 1983\n",
      "   963 3363  830  590    2  830 2023    6  830    2 2014  963 1209  830\n",
      "     2    6    2 2014    6  590  830   13 3363 1331    2   13 1983 1657\n",
      "  1479  963  590  590   13 1604 3363    2    6 3363 1095    2 1604 1209\n",
      "     2 1148 1604 1206 1479  590  963    2  830 2023  963    2 2014  963\n",
      "  1331  963 3363 1095    6 1479 5135    2  590 1604 1206 3363 1095  830\n",
      "  1479    6 1148 2295    2    6 3363 1095    2  503    6 1148 2295 1331\n",
      "  1479 1604 1206 3363 1095    2  590 1148 1604 1479  963    2]]\n",
      "[8.392782e-07]\n",
      "So does the 2019 version of Lion King match up? (In India, the film is releasing in four languages â€“ English and also dubbed in Hindi, Tamil and Telegu.) The big draw of course of the Hindi dubbed version is actor Shah Rukh Khan as Mufasa and Aryan Khan as Simba. The father and son duo had earlier lent their voices to the Hindi dubbed version of The Incredibles in 2004.\n",
      "\n",
      "[[ 503  503  963 1095    2   13 3363    2    2   13 3363 1095   13    2\n",
      "     2    6 1983   13 2014    2    6 3363 1095    2    2  963 2014  963\n",
      "  1331 1206    2    2    2 2023  963    2  503   13 1331    2 1095 1479\n",
      "     6 1992    2 1604 1209    2 1148 1604 1206 1479  590  963    2 1604\n",
      "  1209    2  830 2023  963    2    2   13 3363 1095   13    2 1095 1206\n",
      "   503  503  963 1095    2 1964  963 1479  590   13 1604 3363    2   13\n",
      "   590    2    6 1148  830 1604 1479    2    2 2023    6 2023    2    2\n",
      "  1206 2295 2023    2    2 2023    6 3363    2    6  590    2    2 1206\n",
      "  1209    6  590    6    2    6 3363 1095    2    2 1479 5135    6 3363\n",
      "     2    2 2023    6 3363    2    6  590    2    2   13 1983  503    6\n",
      "     2    2    2 2023  963    2 1209    6  830 2023  963 1479    2    6\n",
      "  3363 1095    2  590 1604 3363    2 1095 1206 1604    2 2023    6 1095\n",
      "     2  963    6 1479 2014   13  963 1479    2 2014  963 3363  830    2\n",
      "   830 2023  963   13 1479    2 1964 1604   13 1148  963  590    2  830\n",
      "  1604    2  830 2023  963    2    2   13 3363 1095   13    2 1095 1206\n",
      "   503  503  963 1095    2 1964  963 1479  590   13 1604 3363    2 1604\n",
      "  1209    2    2 2023  963    2    2 3363 1148 1479  963 1095   13  503\n",
      "  2014  963  590    2   13 3363    2  241 2241 2241  470    2]]\n",
      "[5.0536454e-07]\n",
      "2019â€™s Lion King is a visual extravaganza to savor. Everything you see on screen is etched out with spellbinding detailing and the visual finesse gives way to near perfection. Some scenes especially ones with the fire flies in the night, open starlit skies and expansive views of the forest look stunning. Where the visual appeal falls short is in the expressions and emotions on the faces, especially the eyes of the animals which the animated version had got so right. So while you do feel sad when Mufasa is killed, you are not particularly moved to tears like with the original. And while Scar looks evil, he is not menacing. Also though the film is thirty minutes lengthier it pretty much remains an almost scene by scene copy of the 1994 version, losing its potential to surprise and intrigue further.\n",
      "\n",
      "[[   6 1479  590    2 2014   13 2295  963    2 1992   13  830 2023    2\n",
      "   830 2023  963    2 1604 1479   13 1331   13 3363    6 2014    2    2\n",
      "     2 3363 1095    2 1992 2023   13 2014  963    2    2 1148    6 1479\n",
      "     2 2014 1604 1604 2295  590    2  963 1964   13 2014    2 2023  963\n",
      "     2   13  590    2 3363 1604  830    2 1983  963 3363    6 1148   13\n",
      "  3363 1331    2    2    2 2014  590 1604    2  830 2023 1604 1206 1331\n",
      "  2023    2  830 2023  963    2 1209   13 2014 1983    2   13  590    2\n",
      "   830 2023   13 1479  830 5135    2 1983   13 3363 1206  830  963  590\n",
      "     2 2014  963 3363 1331  830 2023   13  963 1479    2   13  830    2\n",
      "  1657 1479  963  830  830 5135    2 1983 1206 1148 2023    2 1479  963\n",
      "  1983    6   13 3363  590    2    6 3363    2    6 2014 1983 1604  590\n",
      "   830    2  590 1148  963 3363  963    2  503 5135    2  590 1148  963\n",
      "  3363  963    2 1148 1604 1657 5135    2 1604 1209    2  830 2023  963\n",
      "     2  300  790  790  470    2 1964  963 1479  590   13 1604 3363    2\n",
      "  2014 1604  590   13 3363 1331    2   13  830  590    2 1657 1604  830\n",
      "   963 3363  830   13    6 2014    2  830 1604    2  590 1206 1479 1657\n",
      "  1479   13  590  963    2    6 3363 1095    2   13 3363  830 1479   13\n",
      "  1331 1206  963    2 1209 1206 1479  830 2023  963 1479    2]]\n",
      "[7.550299e-06]\n",
      "However, the principal voice cast is a delight â€“ Shah Rukh Khan as Mufasa is captivating from the word go, Aryan Khan shines as the young Simba â€“ capturing every emotion perfectly. The scene where Simba speaks to his fatherâ€™s reflection in the water, with Mufasaâ€™s voice emanating from the sky stands out as a whole â€“ visually and otherwise. Ashish Vidyarthi as Scar is particularly good, his voice adding the required dimension to the character.Perhaps to contextualize andgive it a local flavor Pumbaa (Sanjay Mishra) and Timon (Shreyas Talpade) speak in tapori hindi here â€“ so there is a generous sprinkling of â€˜Bhaiâ€™ â€˜Jhakaasâ€™ â€˜ Apunâ€™ â€˜Bindassâ€™. And the gang of hyenas speak in Bhojpuri.While it may connect with the audience and elucidate some laughs, it robs the classic film of some of its original flavor.\n",
      "\n",
      "[[1604    2  830 2023  963 1479  963    2   13  590    2    6    2 1331\n",
      "   963 3363  963 1479 1604 1206  590    2  590 1657 1479   13 3363 2295\n",
      "  2014   13 3363 1331    2 1604 1209    2    2    2    2    2 2023    6\n",
      "    13    2    2    2    2    2    2    2    2 2023    6 2295    6    6\n",
      "   590    2    2    2    2    2    2    2    2    2 1657 1206 3363    2\n",
      "     2    2    2    2    2    2    2   13 3363 1095    6  590  590    2\n",
      "     2    2    2    2    2 3363 1095    2  830 2023  963    2 1331    6\n",
      "  3363 1331    2 1604 1209    2 2023 5135  963 3363    6  590    2  590\n",
      "  1657  963    6 2295    2   13 3363    2    2 2023 1604 1468 1657 1206\n",
      "  1479   13    2    2 2023   13 2014  963    2   13  830    2 1983    6\n",
      "  5135    2 1148 1604 3363 3363  963 1148  830    2 1992   13  830 2023\n",
      "     2  830 2023  963    2    6 1206 1095   13  963 3363 1148  963    2\n",
      "     6 3363 1095    2  963 2014 1206 1148   13 1095    6  830  963    2\n",
      "   590 1604 1983  963    2 2014    6 1206 1331 2023  590    2   13  830\n",
      "     2 1479 1604  503  590    2  830 2023  963    2 1148 2014    6  590\n",
      "   590   13 1148    2 1209   13 2014 1983    2 1604 1209    2  590 1604\n",
      "  1983  963    2 1604 1209    2   13  830  590    2 1604 1479   13 1331\n",
      "    13 3363    6 2014    2 1209 2014    6 1964 1604 1479    2]]\n",
      "[3.462267e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shreya Ghosal, Arman Malik and Sunayna Sarkar do a fine job with the Hindi renditions of the soundtrack. But for those who have reveled in the original 'Circle of Life', 'Can you feel the Love tonight' and 'Hakuna Matata' it may not match up totally. The background score by Hans Zimmer is one of the high points of the film.\n",
      "\n",
      "[[   2 1479  963 3363 1095   13  830   13 1604 3363  590    2 1604 1209\n",
      "     2  830 2023  963    2  590 1604 1206 3363 1095  830 1479    6 1148\n",
      "  2295    2    2    2 1206  830    2 1209 1604 1479    2  830 2023 1604\n",
      "   590  963    2 1992 2023 1604    2 2023    6 1964  963    2 1479  963\n",
      "  1964  963 2014  963 1095    2   13 3363    2  830 2023  963    2 1604\n",
      "  1479   13 1331   13 3363    6 2014    2  758    2   13 1479 1148 2014\n",
      "   963    2 1604 1209    2    2   13 1209  963  758    2  758    2    6\n",
      "  3363    2 5135 1604 1206    2 1209  963  963 2014    2  830 2023  963\n",
      "     2    2 1604 1964  963    2  830 1604 3363   13 1331 2023  830  758\n",
      "     2    6 3363 1095    2  758    2    6 2295 1206 3363    6    2    2\n",
      "     6  830    6  830    6  758    2   13  830    2 1983    6 5135    2\n",
      "  3363 1604  830    2 1983    6  830 1148 2023    2 1206 1657    2  830\n",
      "  1604  830    6 2014 2014 5135    2    2    2 2023  963    2  503    6\n",
      "  1148 2295 1331 1479 1604 1206 3363 1095    2  590 1148 1604 1479  963\n",
      "     2  503 5135    2    2    6 3363  590    2    2   13 1983 1983  963\n",
      "  1479    2   13  590    2 1604 3363  963    2 1604 1209    2  830 2023\n",
      "   963    2 2023   13 1331 2023    2 1657 1604   13 3363  830  590    2\n",
      "  1604 1209    2  830 2023  963    2 1209   13 2014 1983    2]]\n",
      "[9.571896e-07]\n",
      "For those who havenâ€™t seen the original, 'The Lion King' (2019) is certainly worth a watch for its gorgeous visuals and technical genius and oneâ€™s catching it in Hindi will have Shah Rukh Khan and Aryan Khan adding their spark.\n",
      "[[   1    2 1604 1479    2  830 2023 1604  590  963    2 1992 2023 1604\n",
      "     2 2023    6 1964  963 3363    2    2    2  830    2  590  963  963\n",
      "  3363    2  830 2023  963    2 1604 1479   13 1331   13 3363    6 2014\n",
      "     2  758    2 2023  963    2    2   13 1604 3363    2    2   13 3363\n",
      "  1331  758    2  241 2241  300  790    2   13  590    2 1148  963 1479\n",
      "   830    6   13 3363 2014 5135    2 1992 1604 1479  830 2023    2    6\n",
      "     2 1992    6  830 1148 2023    2 1209 1604 1479    2   13  830  590\n",
      "     2 1331 1604 1479 1331  963 1604 1206  590    2 1964   13  590 1206\n",
      "     6 2014  590    2    6 3363 1095    2  830  963 1148 2023 3363   13\n",
      "  1148    6 2014    2 1331  963 3363   13 1206  590    2    6 3363 1095\n",
      "     2 1604 3363  963    2    2    2  590    2 1148    6  830 1148 2023\n",
      "    13 3363 1331    2   13  830    2   13 3363    2    2   13 3363 1095\n",
      "    13    2 1992   13 2014 2014    2 2023    6 1964  963    2    2 2023\n",
      "     6 2023    2    2 1206 2295 2023    2    2 2023    6 3363    2    6\n",
      "  3363 1095    2    2 1479 5135    6 3363    2    2 2023    6 3363    2\n",
      "     6 1095 1095   13 3363 1331    2  830 2023  963   13 1479    2  590\n",
      "  1657    6 1479 2295    2    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[1.4674962e-05]\n"
     ]
    }
   ],
   "source": [
    "#testing your own reviews\n",
    "model = keras.models.load_model(\"model.h5\")\n",
    "\n",
    "def review_encode(s):\n",
    "    encoded = [1]\n",
    "    for word in s:\n",
    "        if word in word_index:\n",
    "            encoded.append(word_index[word])\n",
    "        else:\n",
    "            encoded.append(2)\n",
    "    return encoded\n",
    "\n",
    "with open(\"review.txt\") as f:\n",
    "    for line in f.readlines():\n",
    "        nline = line.replace(\",\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").strip()\n",
    "        encode = review_encode(nline)\n",
    "        encode = keras.preprocessing.sequence.pad_sequences([encode], value=word_index['<PAD>'], padding='post', maxlen=250)\n",
    "        predict = model.predict(encode)\n",
    "        print(line)\n",
    "        print(encode)\n",
    "        print(predict[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
